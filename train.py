import argparse
import os
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
from typing import Optional

# Custom Modules
from dataset import get_dataloader
from model import Unet
from diffusion.ddpm import DDPM
from utils import setup_seed, save_images, EMA, prepare_logging

def train(args):
    # ==========================================================================================
    # 1. ì´ˆê¸° ì„¤ì • (Setup)
    # ==========================================================================================
    setup_seed(args.seed) # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Training on {device} with seed {args.seed}")
    
    
    if device.type == 'cuda':
        torch.backends.cudnn.benchmark = True
        print(f"   - GPU: {torch.cuda.get_device_name(0)}")

    # ==========================================================================================
    # 2. ë¡œê¹… ë° ì €ì¥ ê²½ë¡œ ì„¤ì • (Logging)
    # ==========================================================================================
    # results/ì‹¤í—˜ì´ë¦„/samples, results/ì‹¤í—˜ì´ë¦„/checkpoints í´ë” ìƒì„±
    run_dir = os.path.join(args.result_dir, args.run_name)
    os.makedirs(run_dir, exist_ok=True)
    sample_dir = os.path.join(run_dir, 'samples')
    ckpt_dir = os.path.join(run_dir, 'checkpoints')
    os.makedirs(sample_dir, exist_ok=True)
    os.makedirs(ckpt_dir, exist_ok=True)
    
    logger = prepare_logging(args.run_name)
    
    # ==========================================================================================
    # 3. ë°ì´í„° ë¡œë“œ (Data Loading)
    # ==========================================================================================
    print("ğŸ“š Loading Dataset...")
    # dataset.pyì˜ get_dataloader ì‚¬ìš© (ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬ í¬í•¨)
    dataloader = get_dataloader(
        batch_size=args.batch_size,
        num_workers=args.num_workers
    )
    
    # [Safety Check] ë°ì´í„°ê°€ [-1, 1] ë²”ìœ„ë¡œ ì˜ ì •ê·œí™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
    # DDPMì€ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ(í‰ê·  0, ë¶„ì‚° 1)ë¥¼ ë‹¤ë£¨ë¯€ë¡œ ì…ë ¥ ë°ì´í„°ë„ -1~1 ë²”ìœ„ì—¬ì•¼ ì„±ëŠ¥ì´ ë‚˜ì˜´
    sample_img, _ = next(iter(dataloader))
    if sample_img.min() < -1.1 or sample_img.max() > 1.1:
        print(f"âš ï¸ Warning: Data range seems off. Min: {sample_img.min():.2f}, Max: {sample_img.max():.2f}")
        print("   - Expected range: [-1, 1]")
    else:
        print(f"âœ… Data range verified: [{sample_img.min():.2f}, {sample_img.max():.2f}]")

    # ==========================================================================================
    # 4. ëª¨ë¸ ë° ìµœì í™” ì„¤ì • (Model & Optimizer)
    # ==========================================================================================
    print("ğŸ—ï¸ Initializing Model...")

    model = Unet(
        dim=64,                # ê¸°ë³¸ ì±„ë„ ìˆ˜
        channels=3,            # RGB
        dim_mults=(1, 2, 2, 4),# ì±„ë„ ì¦í­ ë¹„ìœ¨ (64 -> 128 -> 128 -> 256)
        with_time_emb=True
    ).to(device)

    # DDPM Wrapper(Scheduler & Loss Calculation)
    ddpm = DDPM(
        denoise_model=model,
        timesteps=args.timesteps,
        beta_start=args.beta_start,
        beta_end=args.beta_end,
        loss_type='l2'  #MSE Loss
    ).to(device)
    
    # Optimizer(AdamWê°€ Adamë³´ë‹¤ weight decayê°€ ë” íš¨ê³¼ì )
    optimizer = optim.AdamW(model.parameters(), lr=args.lr)
    
    # EMA (Exponential Moving Average)(Optional)
    # í•™ìŠµ ì¤‘ì¸ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì˜ ì´ë™ í‰ê· ì„ ë³„ë„ë¡œ ì €ì¥.
    # ìƒì„±(Inference) ì‹œì—ëŠ” ì´ EMA ëª¨ë¸ì„ ì“°ëŠ” ê²ƒì´ í’ˆì§ˆì´ í›¨ì”¬ ì¢‹ìŒ.
    ema: Optional[EMA] = None
    if args.use_ema:
        ema = EMA(model, beta=0.9999)
        ema.register()  #í˜„ì¬ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìƒíƒœë¥¼ EMAì— ë“±ë¡
        print("   - EMA Enabled (beta=0.9999)")

    # Mixed Precision(AMP): ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ
    scaler = GradScaler(enabled=args.amp)
    if args.amp:
        print("   - Mixed Precision (AMP) Enabled")

    # ==========================================================================================
    # 5. í•™ìŠµ ë£¨í”„ (Training Loop)
    # ==========================================================================================
    global_step = 0
    total_steps = args.max_steps
    
    print(f"ğŸ Starting Training for {total_steps} steps...")
    
    while global_step < total_steps:
        # DataloaderëŠ” epoch ë‹¨ìœ„ë¡œ ëŒë¦¬ì§€ë§Œ, DDPMì€ step ë‹¨ìœ„ë¡œ ì œì–´
        for i, (images, _) in enumerate(dataloader):
            if global_step >= total_steps:
                break
            
            optimizer.zero_grad()
            
            images = images.to(device)
            
            # Forward Pass
            # autocast: ì—°ì‚°ì— ë”°ë¼ float16ê³¼ float32ë¥¼ ìë™ìœ¼ë¡œ ì„ì–´ ì“´ë‹¤
            with autocast(enabled=args.amp):
                # ddpm(images) -> p_losses() -> MSE(noise, pred_noise)
                loss = ddpm(images)
            
            # Backward & Optimization
            # scaler.scale: lossì— ìŠ¤ì¼€ì¼ì„ ê³±í•´ underflow ë°©ì§€
            scaler.scale(loss).backward()
            
            # Gradient Clipping(ì•ˆì •ì  í•™ìŠµ í•„ìˆ˜)
            if args.grad_clip > 0:
                scaler.unscale_(optimizer) # clipping ì „ unscale
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            
            # Optimizer step
            scaler.step(optimizer)
            scaler.update()
            
            # EMA Update : ë§¤ ìŠ¤í…ë§ˆë‹¤ ì¡°ê¸ˆì”© ì´ë™ í‰ê·  ì—…ë°ì´íŠ¸
            if ema is not None:
                ema.update()
            
            # Logging
            if global_step % args.log_interval == 0:
                print(f"[Step {global_step}/{total_steps}] Loss: {loss.item():.4f}")
                logger.info(f"Step {global_step} Loss: {loss.item():.4f}")
            
            # Save Checkpoint
            if global_step % args.save_interval == 0 and global_step > 0:
                ckpt_path = os.path.join(ckpt_dir, f"ckpt_step_{global_step}.pt")
                save_dict = {
                    'step': global_step,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'args': args
                }
                if ema is not None:
                    save_dict['ema_state_dict'] = ema.shadow
                
                torch.save(save_dict, ckpt_path)
                print(f"ğŸ’¾ Checkpoint saved: {ckpt_path}")
                
            # Sampling
            if global_step % args.sample_interval == 0 and global_step > 0:
                print(f"âœ¨ Sampling {args.num_samples} images at step {global_step}...")
                
                # EMA Modelë¡œ ìƒ˜í”Œë§ (ê¶Œì¥)
                # 1. í˜„ì¬ í•™ìŠµ ì¤‘ì¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ema ê°€ì¤‘ì¹˜ë¡œ ì ì‹œ êµì²´
                eval_model = model
                if ema is not None:
                    ema.apply_shadow() # Apply EMA weights
                    
                # 2. ì´ë¯¸ì§€ ìƒì„±(Inference)
                with torch.no_grad():
                    # ddpm.sample ë‚´ë¶€ì—ì„œ p_sample_loop í˜¸ì¶œ (tqdm í¬í•¨)(reverse process)
                    sampled_images = ddpm.sample(
                        shape=(args.num_samples, 3, 32, 32)
                    )
                
                # Save Image
                save_path = os.path.join(sample_dir, f"sample_step_{global_step}.png")
                # [-1, 1] -> [0, 1] ë³€í™˜ì€ save_images ë‚´ë¶€ì—ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜ ì—¬ê¸°ì„œ ì²˜ë¦¬
                # utils.save_imagesê°€ (B, C, H, W)ë¥¼ ë°›ì•„ ì €ì¥í•œë‹¤ê³  ê°€ì • (ë³´í†µ 0~1 or -1~1 ì˜ˆìƒ)
                # ì—¬ê¸°ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ [0, 1]ë¡œ ë³€í™˜í•˜ì—¬ ë„˜ê¸°ëŠ” ê²ƒì´ ì•ˆì „
                sampled_images = (sampled_images + 1) * 0.5
                sampled_images = torch.clamp(sampled_images, 0, 1)
                
                save_images(sampled_images, save_path)
                print(f"ğŸ–¼ï¸ Sample saved: {save_path}")
                
                # EMA ë³µì›
                if ema is not None:
                    ema.restore()
            
            global_step += 1
            
    # Final Save
    final_ckpt_path = os.path.join(ckpt_dir, "ckpt_final.pt")
    save_dict = {
        'step': total_steps,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'args': args
    }
    if ema is not None:
        save_dict['ema_state_dict'] = ema.shadow
    torch.save(save_dict, final_ckpt_path)
    print("ğŸ† Training Complete!")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="DDPM Training - CIFAR10")
    
    # Training Hyperparameters
    parser.add_argument('--run_name', type=str, default='ddpm_cifar10_exp1', help='Experiment name')
    parser.add_argument('--max_steps', type=int, default=800000, help='Total training steps')
    parser.add_argument('--batch_size', type=int, default=128, help='Batch size')
    parser.add_argument('--lr', type=float, default=2e-4, help='Learning rate')
    
    # DDPM Hyperparameters
    parser.add_argument('--timesteps', type=int, default=1000, help='Diffusion timesteps')
    parser.add_argument('--beta_start', type=float, default=1e-4)
    parser.add_argument('--beta_end', type=float, default=0.02)
    
    # Advanced Options
    parser.add_argument('--amp', action='store_true', help='Enable Mixed Precision Training')
    parser.add_argument('--grad_clip', type=float, default=1.0, help='Gradient clipping value')
    parser.add_argument('--use_ema', type=str, default='true', choices=['true', 'false'], help='Use EMA')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    
    # Logging & Saving
    parser.add_argument('--result_dir', type=str, default='./results')
    parser.add_argument('--log_interval', type=int, default=100, help='Log loss every N steps')
    parser.add_argument('--save_interval', type=int, default=5000, help='Save checkpoint every N steps')
    parser.add_argument('--sample_interval', type=int, default=2000, help='Sample images every N steps')
    parser.add_argument('--num_samples', type=int, default=16, help='Number of images to sample')
    parser.add_argument('--num_workers', type=int, default=4, help='DataLoader workers')

    args = parser.parse_args()
    
    # Boolean parsing correction
    args.use_ema = args.use_ema.lower() == 'true'
    
    train(args)
