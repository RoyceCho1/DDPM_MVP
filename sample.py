import argparse
import os
import torch
import math
from tqdm import tqdm

from model import Unet
from diffusion.ddpm import DDPM
from utils import setup_seed, save_images

def sample(args):
    # 1. í™˜ê²½ ì„¤ì • (Setup)
    # ì‹¤í—˜ ìž¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •
    setup_seed(args.seed)
    
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("CUDA not available, switching to CPU.")
        device = torch.device('cpu')
    else:
        device = torch.device(args.device)
        
    print(f"Sampling on {device} with seed {args.seed}")
    
    # 2. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (Load Checkpoint)
    if not os.path.exists(args.checkpoint):
        raise FileNotFoundError(f"Checkpoint not found: {args.checkpoint}")
        
    print(f"Loading checkpoint: {args.checkpoint}")
    # map_locationì„ ì‚¬ìš©í•˜ì—¬ ì €ìž¥ëœ ê¸°ê¸°ì™€ ë‹¤ë¥¸ ê¸°ê¸°ì—ì„œë„ ë¡œë“œ ê°€ëŠ¥í•˜ê²Œ í•¨
    ckpt = torch.load(args.checkpoint, map_location=device)
    # í•™ìŠµ ë‹¹ì‹œì˜ ì„¤ì •ê°’ë“¤(args)ì„ ê°€ì ¸ì˜´
    train_args = ckpt['args']
    
    # 3. ëª¨ë¸ ì´ˆê¸°í™” (Model Init)
    # train.pyì—ì„œëŠ” ëª¨ë¸ êµ¬ì¡°ë¥¼ í•˜ë“œì½”ë”©í•¨:
    # dim=64, dim_mults=(1,2,2,4), channels=3, with_time_emb=True
    # ì´ ê°’ë“¤ì€ argparse argsì— ì €ìž¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ,
    # inference ì‹œ ë™ì¼í•œ ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ìž¬í˜„í•´ì•¼ í•¨.
    dim = getattr(train_args, 'dim', 64)    # ì•ˆì „ìž¥ì¹˜ìš©(ì‹¤ì œë¡œëŠ” ì‚¬ìš© ì•ˆë¨)
    
    print("ðŸ—ï¸ Initializing Model...")
    # train.pyì—ì„œ í•˜ë“œì½”ë”©í–ˆë˜ ê°’ë“¤ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    model = Unet(
        dim=64,                  # train.pyì™€ ë™ì¼
        channels=3,              # CIFAR-10 RGB
        dim_mults=(1, 2, 2, 4),   # train.pyì™€ ë™ì¼
        with_time_emb=True
    ).to(device)

    # DDPM ì„¤ì • ê°’ ì¶”ì¶œ
    timesteps = getattr(train_args, 'timesteps', 1000)
    beta_start = getattr(train_args, 'beta_start', 1e-4)
    beta_end = getattr(train_args, 'beta_end', 0.02)
    
    # DDPM ì´ˆê¸°í™”
    ddpm = DDPM(
        denoise_model=model,
        timesteps=timesteps,
        beta_start=beta_start,
        beta_end=beta_end,
        loss_type='l2'
    ).to(device)
    
    # ==========================================================================================
    # 4. Load Weights (EMA vs Standard)
    # ==========================================================================================
    loaded_ema = False
    
    # ì‚¬ìš©ìžê°€ EMA ê°€ì¤‘ì¹˜ ì‚¬ìš©ì„ ì›í•˜ê³ , ì²´í¬í¬ì¸íŠ¸ì— EMA ë°ì´í„°ê°€ ìžˆë‹¤ë©´ ìš°ì„  ë¡œë“œ
    if args.use_ema:
        if 'ema_state_dict' in ckpt:
            print("âœ¨ Loading EMA weights for better quality...")
            # ddpm.denoise_modelì€ ìœ„ì—ì„œ ë§Œë“  model ê°ì²´ë¥¼ ê°€ë¦¬í‚¤ë¯€ë¡œ,
            # EMA ê°€ì¤‘ì¹˜ë¥¼ ì´ ê°ì²´ì— ë¡œë“œí•¨
            ddpm.denoise_model.load_state_dict(ckpt['ema_state_dict'])
            loaded_ema = True
        else:
            print("âš ï¸ EMA weights requested but not found in checkpoint. Loading standard weights.")
            ddpm.denoise_model.load_state_dict(ckpt['model_state_dict'])
    else:
        # EMAë¥¼ ë„ê±°ë‚˜ ì²´í¬í¬ì¸íŠ¸ì— ì—†ëŠ” ê²½ìš° ì¼ë°˜ weight ë¡œë“œ
        print("Standard weights loaded (EMA disabled).")
        ddpm.denoise_model.load_state_dict(ckpt['model_state_dict'])
    
    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    ddpm.eval()
    
    # ==========================================================================================
    # 5. Generation Loop
    # ==========================================================================================
    os.makedirs(args.output_dir, exist_ok=True)
    
    total_samples = args.num_samples
    # ì „ì²´ ìƒ˜í”Œ ìˆ˜ë¥¼ ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ ì„œ ëª‡ ë²ˆ ë£¨í”„ë¥¼ ëŒì§€ ê³„ì‚°
    batches = math.ceil(total_samples / args.batch_size)
    all_images = []
    generated_count = 0
    
    print(f"ðŸŽ¨ Generating {total_samples} samples in {batches} batches...")
    
    with torch.no_grad():
        for i in tqdm(range(batches), desc="Sampling Batches"):
            # Calculate exact batch size (Bug Fix: use generated_count)
            current_bs = min(args.batch_size, total_samples - generated_count)
            
            # Sampling (reverse process) -> [-1, 1]
            imgs = ddpm.sample(shape=(current_bs, 3, 32, 32))
            
            all_images.append(imgs.cpu())
            generated_count += current_bs
            
    # Concatenate all batches
    all_images = torch.cat(all_images, dim=0)
    
    # [-1, 1] -> [0, 1] Conversion (Consistency)
    all_images = (all_images + 1) * 0.5
    
    # 6. Save Result
    save_filename = f"sample_{args.num_samples}_seed{args.seed}"
    if loaded_ema:
        save_filename += "_ema"
    save_filename += ".png"
    
    save_path = os.path.join(args.output_dir, save_filename)
    
    print(f"ðŸ’¾ Saving grid image to {save_path}...")
    # save_images now expects [0, 1]
    save_images(all_images, save_path, nrow=args.grid_nrow)
    
    print("âœ… Done!")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="DDPM Inference - CIFAR10")
    
    parser.add_argument('--checkpoint', type=str, required=True, help='Path to checkpoint (.pt)')
    parser.add_argument('--output_dir', type=str, default='./generated', help='Output directory')
    parser.add_argument('--num_samples', type=int, default=64, help='Total number of images to generate')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for generation')
    parser.add_argument('--grid_nrow', type=int, default=8, help='Images per row in grid')
    parser.add_argument('--device', type=str, default='cuda', help='Device to use (cuda/cpu)')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    parser.add_argument('--use_ema', type=str, default='true', choices=['true', 'false'], help='Use EMA weights if available')
    
    args = parser.parse_args()
    args.use_ema = args.use_ema.lower() == 'true'
    
    sample(args)
