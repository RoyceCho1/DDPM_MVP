import torch
import torch.nn as nn
from diffusion.ddpm import DDPM

class DummyUNet(nn.Module):
    """
    í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ U-Net
    ì…ë ¥ê³¼ ë™ì¼í•œ í¬ê¸°ì˜ ì¶œë ¥ì„ ë‚´ë±‰ìŒ.
    """
    def forward(self, x, t):
        # Time embedding etc.ëŠ” ìƒëµí•˜ê³  ë‹¨ìˆœíˆ ì¶œë ¥ shapeë§Œ ë§ì¶¤
        return torch.randn_like(x) * 0.1

def test_ddpm():
    print("ğŸ§ª Testing DDPM Wrapper...")
    
    # 1. Setup
    if torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')
    print(f"Device: {device}")
    
    # ë”ë¯¸ ëª¨ë¸ ìƒì„±
    unn = DummyUNet()
    
    # DDPM ì´ˆê¸°í™”
    # ìˆ˜ì •ëœ __init__ ì‹œê·¸ë‹ˆì²˜ ë°˜ì˜ (denoise_model -> denoise_model (but stored as self.model))
    ddpm = DDPM(
        denoise_model=unn,
        timesteps=100, # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‘ê²Œ ì„¤ì •
    )
    ddpm.to(device) # .to(device) í˜¸ì¶œ ì‹œ ë‚´ë¶€ ë²„í¼ë“¤ë„ ì´ë™í•˜ëŠ”ì§€ í™•ì¸
    print("âœ… DDPM Initialized and moved to device.")
    
    # 2. Test Training Step (Forward Path)
    B = 4
    x = torch.randn(B, 3, 32, 32).to(device)
    
    loss = ddpm(x)
    print(f"âœ… Training Step Loss: {loss.item()}")
    
    # Gradient Check
    loss.backward()
    print("âœ… Backward pass successful.")
    
    # 3. Test Sampling Step (Reverse Path)
    print("Generating samples...")
    shape = (2, 3, 16, 16)
    
    # sample í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ deviceë¥¼ ì˜ ì¶”ë¡ í•˜ëŠ”ì§€ í™•ì¸
    samples = ddpm.sample(shape)
    
    print(f"âœ… Generated Sample Shape: {samples.shape}")
    print(f"âœ… Sample Device: {samples.device}")
    
    assert samples.device.type == device.type, f"Device mismatch! Expected {device}, got {samples.device}"
    
    print("ğŸ‰ DDPM Wrapper Test Passed!")

if __name__ == "__main__":
    test_ddpm()
